{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day14 - Data Manipulation using Pandas (Part2 - Working with CSV)\n",
    "\n",
    "- Pandas is an open-source Python Library providing high-performance data manipulation and analysis tool using its powerful data structures.\n",
    "- Self Learning Resource\n",
    "    - Pandas in 10 Minutes: <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\"> Click Here </a>\n",
    "    - Video1: https://www.youtube.com/watch?v=QUClKFFn1Vk\n",
    "    - Video2: https://www.youtube.com/watch?v=tW1BWtQRZ2M\n",
    "    - Video3: https://www.youtube.com/watch?v=xx4Vkc5RrWY\n",
    "    \n",
    "\n",
    "\n",
    "##### Note: \n",
    "1. First Clean the Evironment (Go to \"Kernel\" Menu --> \"Restart & Clean Output\"\n",
    "2. To execute the code --> Click on a cell and press cntrl + enter key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Red'> 1. Working with data file (csv)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data14.csv')\n",
    "print(\"type(df)-->\",type(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datatype of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read files\n",
    "\n",
    "# To Read CSV  file  --> pd.read_csv()\n",
    "# To Read Excel file --> pd.read_excel()\n",
    "# To Read Json  file --> pd.read_json()\n",
    "# To Read HTML  file --> pd.read_html()\n",
    "\n",
    "# Self learning: How to read data from SQL, MongoDB, Oracle, MySQL using python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Get the dimention of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df.shape -->\", df.shape)\n",
    "print(\"Rows     -->\", df.shape[0])\n",
    "print(\"Columns  -->\", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Show top 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "# Try Also\n",
    "#df.head(10)\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Show bottom 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n",
    "\n",
    "# Try Also\n",
    "#df.tail(10)\n",
    "#df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Select rowz from 51 to 60\n",
    "# Answer: df.head(61).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Get all column names of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n",
    "# Try Also\n",
    "#len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Get the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Get the statistical summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Get the information related to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Transposing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Accessing data from dataset - Part 1 (using loc - Column Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax --> loc[ ROW, COL_Names_in_List ]\n",
    "\n",
    "df.loc[:, ['F1','F3','F6']].head()\n",
    "\n",
    "# Also Try\n",
    "#df.loc[10: , ['F1','F3','F6']]\n",
    "#df.loc[10:100 , ['F1','F3','F6','F7']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.11 Accessing data from dataset - Part 2 (using iloc - Column position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Syntax --> iloc[ ROW, COL_Position]\n",
    "\n",
    "df.iloc[0:10, :5]\n",
    "\n",
    "# Also Try\n",
    "#df.iloc[10:100, :-2]\n",
    "#df.iloc[20:30, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12 To get unique values in a Column (factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['F1'].unique()\n",
    "\n",
    "#len(df['F1'].unique())\n",
    "\n",
    "#df['F4'].unique()\n",
    "\n",
    "#len(df['F4'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.13 To get unique count  in a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['F1'].value_counts()\n",
    "#df['F5'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.14 Selecting data using condition - part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['F4']>10]     # Put NaN where condition is false\n",
    "\n",
    "#df[df['F4']>10].shape\n",
    "\n",
    "#df[(df['F4']>20) & (df['F1'] == 1)].shape\n",
    "\n",
    "#df[(df['F4']>20) | (df['F1'] == 1)].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.15 Selecting data using condition - part 2 (using loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['F4']>20) & (df['F1'] == 1)]\n",
    "\n",
    "#df.loc[(df['F4']>20) & (df['F1'] == 1)].shape     # And\n",
    "\n",
    "#df.loc[(df['F4']>10) | (df['F1'] == 0)].shape     # OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.16 Selecting data using condition - part 3 (using query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('F4 > 20  & F1 == 1')\n",
    "\n",
    "#df.query('F4 > 20  & F1 == 1').shape\n",
    "\n",
    "#df.query('F4 > 10  | F1 == 0').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.17 Selecting data using condition - part 4 (using eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.eval('F4 > 20  & F1 == 1')]\n",
    "\n",
    "#df[df.eval('F4 > 20  & F1 == 1')].shape\n",
    "\n",
    "#df[df.eval('F4 > 10  | F1 == 0')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.18 Get the mean of the all the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()\n",
    "\n",
    "# What is the output?\n",
    "#df.head(50).mean()\n",
    "#df.tail(50).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.19 Get the correlation of the all the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()\n",
    "\n",
    "# Note\n",
    "# 1. Shows the relationship between two objects (or data columns)\n",
    "# 2. Correlation value lies between -1 and +1\n",
    "# 3. If correlation of two columns (Features) is greater than 0.8 (or 0.85 or 0.9), \n",
    "#    then we can drop one of the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.20 Get the maximum of each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.21 Get the minimum of each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.22 Get the median of each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.23 Get the standard deviation of each column in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.24 Append the dataset with the same dataset (make the vaules duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df.shape      -->\",df.shape)\n",
    "\n",
    "temp_df = df.append(df)\n",
    "\n",
    "print(\"temp_df.shape -->\",temp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.25 Drop the duplicates present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df.shape      -->\", df.shape , \"Before\")\n",
    "\n",
    "temp_df = df.drop_duplicates()\n",
    "\n",
    "print(\"temp_df.shape -->\",temp_df.shape, \" After droping duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.26 IsNull: This returns true or false depending on the status of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()\n",
    "\n",
    "# Shows True where NULL are present else False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.27 Aggregate of all the values which are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.28 Drop NA values (delete rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new sample dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\"Name\":[\"Iron-Man\",\"Wonder-Woman\",\"Avengers\",\"Ramayan\"],\n",
    "                     \"House\":[\"Marvel\",\"DC Comics\",\"Marvel\",\"Ramanand Sagar\"],\n",
    "                     \"Start\":[np.nan, pd.Timestamp(\"2017-05-15\"), \n",
    "                              pd.NaT, pd.Timestamp(\"1987-01-25\")]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()     # Drop those rows having any \"NA\"\n",
    "                    # But, No change in the original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.29 Drop the columns where there are null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.30 Drop the entire row and column if ALL THE VALUES are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.31 Drop the null values where they are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = 'any') # Similar to df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.32 Fill the null values with '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([[3,np.nan,4,2],[5,2,np.nan,9],\n",
    "                       [np.nan,np.nan,7,np.nan],\n",
    "                       [4,np.nan,5,np.nan]],\n",
    "                        columns=list('PQRS'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)             # Fill ALL \"NA\" value to \"0\"\n",
    "\n",
    "# Try also: To save in the dataset\n",
    "df.fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.33 Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([[3,np.nan,4,2],[5,2,np.nan,9],\n",
    "                       [np.nan,np.nan,7,np.nan],\n",
    "                       [4,np.nan,5,np.nan]],\n",
    "                        columns=list('PQRS'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceValues = {'P':10,'Q':11,'R':12,'S':13}  # Replace the values columnwise\n",
    "\n",
    "df.fillna(replaceValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.34 Fill null values only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(replaceValues, limit = 1)  # Replace first NA value in every column\n",
    "\n",
    "# Try Also\n",
    "# Replace first two NA value in every column and save\n",
    "#df.fillna(replaceValues, limit = 2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.35 Calculated the mean of column (ignore NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P'].mean()       # Find the mean of column 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()            # Find the mean of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,[1,2]].mean()            # Find the mean of 1 and 2 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.36 Filled the missing values with the calculated mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values in one columns with its \"column mean\"\n",
    "mean1 = df['P'].mean()\n",
    "print(mean1)\n",
    "df['P'].fillna(mean1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values in all columns with \"column mean\"\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.37 Describe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.38 Fill the missing values with the mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in the dataset\n",
    "df.fillna(df.mean(), inplace= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.39 Find the correlation between all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.40 Saving dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Test.csv\")\n",
    "\n",
    "# Open Test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.41 Converting dataframe to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
